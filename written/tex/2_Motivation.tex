%!TEX root = ../Main.tex

\section{Selected Estimation and Modelling Procedures for Volatility}\label{sec:2Models}
As mentioned in section \ref{sec:1Intro}, volatility can not be directly observed and thus has to be estimated. This section briefly presents a concept for estimating realized volatility and an approach for modelling volatility, which is able to capture very well the stylized facts observed with financial data.

\subsection{Estimating and Modeling Volatility using Historic Volatility}\label{sec:22Historic}
%
\subsubsection{Estimating Realized Volatility}\label{sec:221RV}
% WHAT IS VOLA%
By definition ``volatility seeks to capture the strength of the (unexpected) return variation over a given period of time'' \parencite[p.7]{andersen2001}. As terminology is not consistent in previous research, in this paper return variance is simply the second moment distribution characteristic, and return volatility its square root, the standard deviation. \\
With volatility being a latent variable, there are multiple concepts for volatility. According to \citeauthor{andersen2001} they can be grouped in (i) the \emph{notional volatility} corresponding to the ex-post sample-path return variability over a fixed time interval, (ii) the ex-ante \emph{expected volatility} over a fixed time interval or the (iii) the \emph{instantaneous volatility} corresponding to the strength of the volatility process at a point in time. Fur the purpose of this paper the notional ex-post sample-path return variability is of importance.\\
Volatility measures usually represent the average volatility over a discrete time period, as a continuous record of price data is not available, and even for very liquid markets, price data are distorted by micro-structure effects. It can however be shown, that under some assumptions the sum of squared high-frequency returns is a consistent estimator for the return variance. This results mainly builds on the work of \parencite{andersen2001} and will only be briefly introduced here.\\
% REALIZED VARIANCE %
To begin with, it should be assumed that we have a continuous-time no-arbitrage setting. As return volatility aims to capture the strength of the unexpected return variation, one needs to define the component of a price change as opposed to an expected price movement. \textcite{andersen2001} show, that under certain assumptions the instantaneous return process can be decomposed into an expected return component, and a martingale innovation (in the discrete time setting this decomposition is more complex, for this paper it shall only be relevant that the martingale part is still the dominant contribution to the return variation over short intervals). Furthermore \textcite{andersen2001} show, that the cumulative sample path variability of this martingale component can be represented by a quadratic variation process, and they define the ex-post measured \emph{notional variance} as the increment to this quadratic variation. Moreover they show, that this notional variance can be consistently estimated, using high-frequency returns or a large sample of returns, with the \emph{realized variance}, defined as:
\begin{align}\label{eq:RV-andersen}
v^2(t,h;n) = \sum_{i=1}^{n} r(t-h+(i/n) \times h,h/n)^2
\end{align}
over any fixed $[t-h,t], 0 < h$ time interval (Their proposition 5) This realized variance is simply the second sample moment of the return process, scaled by the number of observations $n$.\\
So in summary, the increment to the quadratic return variation which is the past variance, can be consistently and well approximated through the accumulation of squared high-frequency returns. Taking the square root of this realized variance, the \emph{realized volatility} is obtained.


\subsubsection{Modelling Volatility - the HAR-RV Model}\label{sec:222HAR-RV}
Having introduced the concept of measuring realized volatility, there are multiple approaches that try to model the volatility process. Although volatility is not directly observable, it has some characteristics that are commonly examined and can be used to build volatility models. \\
% STLYZED FACTS%
These commonly observe stylized facts include for example high excess kurtosis for daily return series, and clustering of return variability, meaning that periods of large volatility seem to be followed by high volatility, and periods of low volatility seem to be followed by low volatility \parencite{tsay2005}. Moreover, the autocorrelations of the square and absolute returns show a very strong persistence over long time periods. If return distributions with regard to different time horizons are observed, they show tail-crossover, thus the shape depends on the time scale. As the time scale increases, the return distribution slowly converges to the normal distribution, however very slowly. Moreover, financial data show evidence of scaling and multi-scaling \textcite{corsi2009}. \\
% INTRO TO HAR-RV MODEL %
There are various modelling approaches for volatility. This paper will refer to the HAR-RV model, based on \textcite{corsi2009}, as it is able to reproduce the stylized facts described very well. The model presents a volatility cascade from low to high frequencies, in which not only daily lagged realized volatility, but also weekly and monthly volatility influence future realized volatility.\\
To start with, a quick note on the terminology should be made. The model assumes that prices follow the standard continuous-time process, represented by the stochastic differential equation
\begin{align}\label{eq:return-process-corsi}
dp(t) = \mu(t)dt + \sigma(t)dW(t), \ 0 \leq t \leq T
\end{align}
where $p(t)$ is the logarithm of the instantaneous price, $\mu$ is a finite variation stochastic process, $W(t)$ standard Brownian motion and $\sigma$ a stochastic process independent of $W(t)$. For this process, the variance is the \emph{integrated variance}, which is integral of the instantaneous variance over the one-day interval
\begin{align}
IV_{t}^{(d)} =  \int_{t-1d}^{t} \sigma^{2}(w)dw, 
\end{align}
and the corresponding volatility it's square root: $\sigma = \sqrt{IV_{t}^{(d)}}$.
\textcite{andersen2001} show, that instead of the abstract martingale representation of the return decomposition that was described in \ref{sec:221RV}, the continuous sample paths can also be represented using stochastic differential equations, as it is done here. Then the integrated variance equals the notional volatility, and can equally be estimated using the sum of squared returns. Thus, the HAR-RV model uses the following approximation for realized volatility over the one-day interval, which will be adopted in this paper:
\begin{align}
RV_{t}^{(d)} = \sqrt{\sum_{j=0}^{M-1} r^{2}_{t-j \times \Delta}}
\end{align}
with $\Delta = 1d/M$ being the sampling frequency and $r^{2}_{t-j \times \Delta}$ defined as the continuously compounded $\Delta$-frequency returns (with $t$ the day and $j$ the time within the day). \\
% HETEROGENEOUS MARKET HYPOTHESIS %
The idea behind the HAR-RV model is closely connected to the \emph{Heterogeneous Market Hypothesis}, which describes the presence of heterogeneity across market participants and was presented by \textcite{mueller1993}. This view of financial markets grounds on the fractal model, introduced and applied to financial markets by \textcite{mandelbrot1963}. The approach of the fractal model is to analyse (time series) objects on different time scales and compare the obtained results. The argument is, that conventional time series analysis, focusing on regularly spaced observations, does not capture the real nature of the raw data, as the usual time choice for recording observations (e.g. a day) is arbitrary. Using this fractal approach and empirical finding of volatility characteristics\footnote{\textcite{mueller1993} observed that the decline of the return autocorrelation function is not exponential, as suggested for example by lower-order GARCH or ARCH models, but rather hyperbolic. Assuming that each of the distinct components has an exponential decline with different time horizons, in sum comes close to a hyperbolic decline. Moreover, if market participants were homogeneous, volatility should be negatively correlated with market activity, as the price should converge to the ``real value''. However, they are positively correlated, which might be explained by the fact that actors react and execute in different market situations \parencite{mueller1993}.}) gave rise to the heterogeneous market hypothesis. This hypothesis states that the market gives rise to heterogeneous trading behaviours since different market participants or components have different time horizons for their trading goals and for their consideration of past events. The time span has on the one end the high-frequency dealers such as market makers, in the middle medium term dealers and on the other end the low-frequency dealers, such as central banks or commercial organizations. Driven by this components, ''the market is heterogeneous with a ''fractal`` structure of the participants' time horizon`` \parencite[p.12]{mueller1993}.\\
% EMPIRICAL JUSTIFICATION OF THE HAR-RV MODEL %
\textcite{corsi2009} adds to the observations of \textcite{mueller1993}, that volatility has an asymmetric behaviour of influence, meaning that volatility over longer time periods has a stronger influence on volatility observed over short periods than conversely. The pattern that emerges from this is a volatility cascade from low to high frequencies. To formalize the model the \emph{latent partial volatility} $\tilde{\sigma}_{t}^{(.)}$ is defined as the volatility generated by a certain market component. To account for short-term, medium-term and long-term traders, the time horizons of one day (1$d$), one week (1$w$) and one month (1$m$) are considered, and denoted by $\tilde{\sigma}_{t}^{(d)}$, $\tilde{\sigma}_{t}^{(m)}$ and $\tilde{\sigma}_{t}^{(w)}$. In the model, each of this volatility components corresponds to a market participant, that forms the expectation for the volatility of one period ahead based on both the observation of the current realized volatility according to the own time frame and on the expectation of the one horizon longer volatility. For example for the market participant with a daily horizon, the latent volatility would be
\begin{align*}
\tilde{\sigma}_{t+1d}^{d} = c^{(d)} + \Phi^{(d)} RV_{t}^{(d)} + \gamma^{(d)} E_{t}[\tilde{\sigma}_{t+1w}^{(w)}] + \tilde{w}_{t+1d}^{(d)},
\end{align*}
where $\tilde{w}_{t+1d}^{(d)}$ is the return innovation. Substitution the latent volatilities of the different horizons and defining the latent volatility as the daily integrated volatility ($\sigma_{t}^{(d)})$, the cascade model can be written as
\begin{align}\label{eq:cascade-model}
\sigma_{t+1d}^{(d)} = c + \beta^{(d)} RV_{t}^{(d)} + \beta^{(w)} RV_{t}^{(w)} + \beta^{(m)} RV_{t}^{(m)} + \tilde{w}_{t+1d}^{(d)},
\end{align}
Observing the volatility data ex-post, $\sigma_{t+1d}^{(d)}$ can be written as the realized volatility, a functional form for time series representation can be written as:
\begin{align}\label{eq:time-series-model}
RV_{t+1d}^{(d)} = c + \beta^{(d)} RV_{t}^{(d)} + \beta^{(w)} RV_{t}^{(w)} + \beta^{(m)} RV_{t}^{(m)} + w_{t+1d} ,
\end{align}
where $w_{t+1d}$ includes the innovation component and the measurement and estimation error. The realized volatility for the weekly and monthly aggregated periods are simply the rolling average over the respective periods.
% SIMULATION RESULTS WITH HAR-RV MODEL %
Using simulated return data, \textcite{corsi2009} shows, that the HAR-RV simulated returns and volatility reproduce the stylized facts mentioned above very well. The data has not only the excess of kurtosis but also the tail cross-over, meaning that the fat tails get thinner as the aggregation level increases. The simulated data is also able to reproduce the long memory of the empirical data. Moreover, using OLS, in-sample and out-of-sample forecast, \textcite{corsi2009} shows, that the past volatility components all have significant information content for one day ahead realized volatility and show good forecasting performance.

\subsection{Estimating Volatility Using Option Price Data}
\subsubsection{The General Idea and Evolution of Implied Volatility}
% INTRO IMPLIED VOLA, EXAMPLES: BS %
Apart from using historic data for volatility modelling, the forward-looking nature of options data can be used to augment the information set. This approach is termed \emph{implied volatility}. The intuition behind implied volatility is, that option prices can be seen as reflecting market participants' expectations of the future movements of the underlying asset. Assuming that the market is efficient, as described by \textcite{fama1970}, and that the asset pricing model is correct, the implied volatility derived from the option prices should not only subsume all information contained in historic volatility but also be a more efficient forecast of future volatility \parencite{jiang2003}. \\
One example for implied volatility is the \emph{\ac{BS} implied volatility}, building on the \ac{BS} asset pricing model as presented by \textcite{black1973}, which uses volatility as one input for pricing options. Having the option prices available on the market, it is possible to extract a value for the expected volatility by inverting the theoretical asset pricing model. \\
% LITERATURE REVIEW (BS) IMPLIED VOLA %
Whereas previous research yielded ambiguous results concerning the informational efficiency and forecasting ability of \ac{BS} implied volatility, more recent research made several methodological and data corrections and found evidence supporting the hypothesis that implied volatility has predictive power for future volatility. These corrections included using longer time series, adapting high-frequency asset returns or using non-overlapping samples \parencite{jiang2003}. \textcite{christensen2001} found that under certain of these measurement errors (such as overlapping samples) statistical tests are no longer meaningful. Correcting for this measurement errors results in support for the hypothesis, that implied volatility subsumes all information contained in historic volatility.\\
% FAILURES OF BS IMPLIED VOLA %
However, even though there is evidence in support of \ac{BS} implied volatility, there are several disadvantages of using the implied volatility with an asset pricing model. One disadvantage is, that the \ac{BS} implied volatility relies mostly on information from at-the-money options, which are generally the most actively traded ones. This, however, fails to incorporate information contained in other options. Moreover and more importantly, testing for the \ac{BS} implied volatility always means testing for market efficiency and the \ac{BS} model jointly. Assumptions of the \ac{BS} model include constant volatility, no transaction costs or taxes, no dividend before option maturity, no arbitrage, continuous trading, constant risk-free interest rate, divisible securities and no short sell \parencite{poon2003}. As it is not possible in this setting to test for market efficiency or the pricing assumptions separately, these tests are subject to model misspecification errors \parencite{jiang2003}. This is why an implied volatility that does not rely on an asset pricing model was introduced. 


\subsubsection{Model-Free Implied Volatility - the VIX}\label{sec:223VIX}
% INTRO MODEL-FREE IMPLIED VOLA %
The idea of model free implied volatility was introduced by \textcite{britten2000} who show that the risk-neutral realized volatiltiy can be derived from a set of options with matching expirations, thus extendending the approach of \textcite{derman1994} \textcite{dupire1994}, \textcite{dupire1997} and \textcite{rubinstein1994} on implied distributions. Contrary to the \ac{BS} implied volatility, no assumptions are made concerning the pricing process. Instead, a complete set of option prices is taken as given and as much information as possible is extracted about the underyling price process \parencite{britten2000}. \\
% BRITTEN PAPER %
\textcite{britten2000} show in an approach resembling a binomial tree, that the probability of the stock price reaching any particular level and of a price move is determined by the initial set of option prices. Moreover they show that the risk-neutral expected sum of squared returns between two dates is given from the set of options expiring on these two dates (their proposition 2). This formula does not use any specific option pricing model to derive implied volatility and is only based on no-arbitrage conditions, therefore it solves the joint-hypothesis problem and tests directly for market efficiency \parencite{jiang2003}. \\
% LITERATURE REVIEW MODEL-FREE IMPLIED VOLA %
Several paper used this result and compared the informational efficiency of model-free implied, \ac{BS} and historic volatility. One paper that examines the information content of model-free implied volatility is \textcite{jiang2003}. They use the approach of \textcite{britten2000}, extend the formula to asset price processes with jumps and test the informational efficiency of this model-free implied volatility in comparison to both \ac{BS} implied and historic volatility, using univariate and encompassing regression analysis. With options data from the \ac{SPX} for the model-free implied volatility calculation and 5-min returns for daily realized volatility, they examine monthly non-overlapping samples of a 6-year sample period between June 1988 and December 1994. Their finding is, that the model-free implied volatility subsumes the information contained in the \ac{BS} implied volatility and past realized volatility. Another example is the paper of \textcite{bakanova2010}. With daily data from crude oil futures between November 1986 and December 2006, he evaluates the information content of model-free implied volatility in comparison to historic volatility, with monthly-overlapping samples as well. Using regression analysis, he comes to the result that implied volatility subsumes the information contained in historical volatility. In contrast to these results is for example \textcite{taylor2010}. With individual stock data from 149 U.S. firms between January 1996 and December 1999, they find that for a one-day-ahead estimation, historic volatility outperforms model-free implied volatility- When however extending the prediction horizon or using the most actively traded options, the option implied volatility is mostly more informative. \\
% VIX INTRODUCTION %
One of the first implemented implied volatility indices is the \ac{VIX} from \ac{CBOE}. It is computed each trading day on a real-time basis, with data available dating back to January 1986. Its introduction in 1993 had the intention to provide both a benchmark for market volatility in the short term, and a volatility index on which futures and options could be written and traded. At this time the \ac{VIX} was based on the \ac{BS} option pricing model using S\&P 100 options, as they where the most actively traded in the U.S. \parencite{whaley1995}. In 2003 the \ac{VIX} adopted to the changes that took place in the options market. First, the \ac{SPX} option market superseded the S\&P 100 options market as the most actively traded option market in the U.S., thus following 2003 the \ac{VIX} was based on \ac{SPX} options. Secondly, option index trading behavior changed. Whereas in the 1990s both call and put index options where equally important, over the years both out-of-the money and at-the-money puts gained popularity since they were increasingly bought by portfolio insurers. Thus the \ac{VIX} started to include out-of-the money options in it's calculation, bringing another advantage compared to \ac{BS} implied volatility \parencite{whaley2008}. Finally, the \ac{VIX} calculation changed in 2003, adopting to the model-free implied volatility approach, which was in 2003 widely used by financial theorists, risk managers, and volatility traders alike \parencite{exchange2009}.\\
% VIX CALCULATION %
The \ac{VIX} is constructed in the way that it eliminates mis-specification and ``smile'' effects thus making it an accurate measurement of implied volatility \parencite{blair2001}. The formula for its calculation is
\begin{align}
\sigma^{2} &= \frac{2}{T} \sum_{i} \frac{\Delta K_{i}}{K_{i}^{2}} e^{RT} Q(K_{i}) - \frac{1}{T} (\frac{F}{K_{0}} - 1)^{2} \label{eq:VIXVola}\\
VIX &= 100 \times \sqrt{ \lbrace T_{1}\sigma^{2}_{1}[\frac{N_{T_{2}} - N_{30}}{N_{t_{2}}-N_{T_{1}}}] + T_{2}\sigma^{2}_{2}[\frac{N_{30} - N_{T_{1}}}{N_{t_{2}}-N_{T_{1}}}] \rbrace \times \frac{N_{365}}{N_{30}}} \label{eq:VIX}
\end{align}
with $T$ the time to expiration, $F$ the forward index level, $K_{0}$ the first strike below the forward index level, $K_{i}$ the strike of the $i^{th}$ out-of-the-money option, $\Delta K_{i}$ the interval between the strike prices, $R$ the risk-free rate, $Q(K_{i})$ the midpoint of bid-ask spread for each option with strike $K_{i}$ and $N$ the number of minutes to expiration of the respective option \parencite{exchange2009}. The \ac{VIX} always uses near- and next-term put and call options, with more than 23 and less than 37 days to expiration. Each week, the options used for calculation roll over to new maturities, thus long-term options become next-term options, and in the following week fall out of the sample. Therefore the \ac{VIX} will always reflect an interpolation of the volatility between these two option maturities \parencite{poon2003}. After the selection of the options for the calculation, the volatility for both the near- and next-term options is calculated, using formula \ref{eq:VIXVola}. Out of this two volatilities, the 30-day-weighted average is calculated (formula \ref{eq:VIX}), so that the \ac{VIX} gives information about the expected volatiltiy over the next 30 days \parencite{exchange2009}. 


%  This requires the decomposition of the return process in an expected and an innovation component. 

%(\textcite{canina1993} for example use only a 4-year range of data from 1983 to 1987)

%Moreover, they show that realized variance can serve as an an unbiased estimator of the expected variance.\\

%plus estimation error ($\sigma_{t+1d}^{(d)} = RV_{t+1d}^{(d)} + w_{a+1d}^{(d)}$),

%= \tilde{w}_{1+d}^{(d)} - w_{1+d}^{(d)}$, thus

% For a very comprehensive overview of the volatility research as was state of the art in 2003, please see \textcite{poon2003}.

%This leads them to their proposition 1, that the expectation of the squared return, conditional on stock price and time, is determined by the initial option prices. Moreover, as this proposition one only infers a one-period forecast conditional on a stock price level, they propose a forecast over any multiperiod interval without conditioning, by showing that the risk-neutral expected sum of squared returns between to dates is given from the set of options expiring on these to dates (their proposition 2).

% conducted forecasts using the model free implied volatility or extended the concept. Here, particularly the paper measuring the information content are relevant.

%, which is critical to the usefullness of the VIX or any other implied volatiltiy index.

%\textcolor{gray} {Sometimes the VIX is called \emph{investor fear gauge}, however it is important to notice that it measures, not causes market volatility. It is true, that using regression analysis \textcite{whaley2008} found, that the rate of change in the VIX and S\&P 500 is asymmetric, with the VIX reacting higher to a drop in the S\&P 500 than its rise, which could be interpreted as a higher fear in the downside then excitement in an up-move. Nevertheless, this correlation must not express causality \parencite{whaley2008}.}

% Thus for example a process explaining monthly price changes could not be applied to daily data and vice versa.

%Other than to time scale, the heterogeneous market hypothesis can be applied to geographical location, degrees of risk aversion, institutional constraints or transactions costs. However, as in \textcite{corsi2009} for this paper the time aspect should be relevant.

%Many studies examined the information content of \ac{BS} implied volatility and it's forecasting ability for future volatility. Earlier studies (for example \textcite{canina1993}) find that implied volatility contains little additional information content compared to historical volatility and has no forecasting ability. In contrast, other studies  support the evidence of implied volatility subsuming the information from historic volatility. These are for example \textcite{day1992}, \textcite{lamoureux1993} or \textcite{jorion1995}.

%All in all, this insights provide a convincing argument why early studies found the forecast of implied volatility to be inefficient \parencite{jiang2003}.